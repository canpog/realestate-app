# Sahibinden Scraper + Vercel Cron Job - FINAL Antigravity Prompt

**Proje:** TR DanÄ±ÅŸman CRM - Background Data Collection System  
**Hedef:** GÃ¼nlÃ¼k Sahibinden.com scraping + Supabase auto-update  
**Scope:** Marmaris villalar SADECE (2+1, 3+1, 4+1, 5+1)  
**Execution Time:** ~50 dakika (Antigravity)  
**Version:** 1.0 PRODUCTION

---

## ğŸ¯ SYSTEM ARCHITECTURE

```
Sahibinden.com
    â†“ (Puppeteer scrape)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Vercel Cron Function        â”‚
â”‚ (GÃ¼nde 1x, 00:00 UTC)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ Parse + Clean
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Supabase market_analysis    â”‚
â”‚ + market_analysis_history   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ Query
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Realestate App              â”‚
â”‚ Price Analysis Module       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ IMPLEMENTATION PLAN

Bu promptu **Antigravity Cloud Code**'a yapÄ±ÅŸtÄ±r ve Ã§alÄ±ÅŸtÄ±r:

```
HEMEN BAÅLA: AÅŸaÄŸÄ±daki promptu Antigravity'ye kopyala
```

---

# ANTIGRAVITY PROMPT - BAÅLANGIÃ‡

```
Merhaba Antigravity!

TR DanÄ±ÅŸman CRM iÃ§in Market Data Collection System kuruyoruz.

PROJE BÄ°LGÄ°SÄ°
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Proje: TR DanÄ±ÅŸman CRM + PortfÃ¶y YÃ¶netimi
Framework: Next.js 14 + Vercel
Database: Supabase PostgreSQL
GitHub: https://github.com/canpog/realestate-app
Production: realestate-app-prod.vercel.app
Local: C:\Users\canpo\OneDrive\MasaÃ¼stÃ¼\realestate-app

SYSTEM Ã–ZET
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
GÃ¼nde 1x (00:00 UTC) Sahibinden.com'dan Marmaris villa verisi Ã§ek
Parse et, temizle, Supabase'e yaz
Realestate App'in Price Analysis iÃ§in kullanmasÄ± iÃ§in hazÄ±rla
History tracking ile eski verileri sakla (future analytics)

---

GÃ–REV 1: SUPABASE SCHEMA GÃœNCELLEMESI
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Supabase SQL Editor'e ÅŸu SQL'leri Ã§alÄ±ÅŸtÄ±r:

\`\`\`sql
-- Market Analysis (GÃ¼ncel veriler)
CREATE TABLE IF NOT EXISTS market_analysis (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    
    -- Lokasyon
    city TEXT NOT NULL,
    district TEXT NOT NULL,
    
    -- Emlak Tipi
    listing_type TEXT NOT NULL, -- 'villa'
    rooms TEXT NOT NULL, -- '2+1', '3+1', '4+1', '5+1'
    age_range TEXT, -- 'new', '0-5_years', '5-10_years', '10+_years'
    
    -- Pazar Verileri
    average_price NUMERIC NOT NULL,
    min_price NUMERIC,
    max_price NUMERIC,
    median_price NUMERIC,
    price_per_sqm NUMERIC,
    
    -- Ä°statistikler
    sample_size INTEGER DEFAULT 1,
    data_source TEXT DEFAULT 'sahibinden.com',
    last_scraped TIMESTAMPTZ DEFAULT NOW(),
    
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Market Analysis History (Eski verileri sakla)
CREATE TABLE IF NOT EXISTS market_analysis_history (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    
    city TEXT NOT NULL,
    district TEXT NOT NULL,
    listing_type TEXT NOT NULL,
    rooms TEXT NOT NULL,
    age_range TEXT,
    
    -- Veriler (o gÃ¼n ne vardÄ±?)
    average_price NUMERIC,
    min_price NUMERIC,
    max_price NUMERIC,
    median_price NUMERIC,
    price_per_sqm NUMERIC,
    sample_size INTEGER,
    
    -- Meta
    snapshot_date TIMESTAMPTZ NOT NULL, -- Hangi gÃ¼n bu veri?
    data_source TEXT DEFAULT 'sahibinden.com',
    
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Scraping Logs (Her Ã§alÄ±ÅŸtÄ±rmanÄ±n logu)
CREATE TABLE IF NOT EXISTS scraping_logs (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    
    -- Bilgi
    city TEXT,
    district TEXT,
    listing_type TEXT,
    
    -- SonuÃ§
    status TEXT, -- 'success', 'failed', 'rate_limited', 'no_data'
    properties_found INTEGER,
    average_price NUMERIC,
    error_message TEXT,
    
    -- Meta
    scraped_at TIMESTAMPTZ DEFAULT NOW(),
    execution_time_ms INTEGER -- KaÃ§ ms sÃ¼rdÃ¼?
);

-- Ä°ndeksler
CREATE INDEX idx_market_analysis_location ON market_analysis(city, district);
CREATE INDEX idx_market_analysis_type ON market_analysis(listing_type, rooms);
CREATE INDEX idx_market_analysis_updated ON market_analysis(updated_at DESC);
CREATE INDEX idx_history_snapshot ON market_analysis_history(snapshot_date DESC);
CREATE INDEX idx_scraping_logs_timestamp ON scraping_logs(scraped_at DESC);
\`\`\`

---

GÃ–REV 2: VERCEL CRON FUNCTION OLUÅTUR
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Yeni dosya oluÅŸtur: api/cron/scrape-sahibinden/route.ts

\`\`\`typescript
import { NextRequest, NextResponse } from 'next/server';
import puppeteer from 'puppeteer-extra';
import StealthPlugin from 'puppeteer-extra-plugin-stealth';
import { createClient } from '@/lib/supabase/server';

// Anti-detection plugin
puppeteer.use(StealthPlugin());

export const dynamic = 'force-dynamic';

interface ScrapedProperty {
  title: string;
  price: number;
  sqm: number;
  rooms: string;
  age?: string;
}

interface MarketStats {
  rooms: string;
  age_range: string;
  average_price: number;
  min_price: number;
  max_price: number;
  median_price: number;
  price_per_sqm: number;
  sample_size: number;
}

// Sahibinden URL builder
function buildSahibindenUrl(
  city: string,
  district: string,
  listingType: string,
  rooms: string
): string {
  // URL Format: sahibinden.com/konut/...
  const params = new URLSearchParams();
  params.append('searchStatuses', 'forSale');
  params.append('properties', listingType === 'villa' ? 'villa' : 'apartment');
  params.append('days', '180'); // Son 6 ay
  
  // Rooms mapping
  const roomsMap: { [key: string]: string } = {
    '2+1': '3',
    '3+1': '4',
    '4+1': '5',
    '5+1': '6',
  };
  
  if (roomsMap[rooms]) {
    params.append('bedrooms', roomsMap[rooms]);
  }
  
  return \`https://www.sahibinden.com/konut/\${city}/\${district}?sort=newest&\${params.toString()}\`;
}

// Puppeteer ile scrape
async function scrapeProperties(
  url: string
): Promise<ScrapedProperty[]> {
  let browser;
  const properties: ScrapedProperty[] = [];
  
  try {
    browser = await puppeteer.launch({
      headless: 'new',
      args: [
        '--no-sandbox',
        '--disable-setuid-sandbox',
        '--disable-dev-shm-usage',
        '--disable-gpu',
      ],
    });

    const page = await browser.newPage();
    
    // User-Agent ayarla
    await page.setUserAgent(
      'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    );
    
    // Timeout: 30 saniye
    page.setDefaultNavigationTimeout(30000);
    
    console.log(\`[Scraper] Fetching: \${url}\`);
    
    try {
      await page.goto(url, { waitUntil: 'networkidle2' });
    } catch (navigationError) {
      console.warn('[Scraper] Navigation timeout (continuing anyway):', navigationError);
    }

    // Ä°lanlarÄ± scrape et
    const scrapedData = await page.evaluate(() => {
      const items: any[] = [];
      
      // Sahibinden listing item selector
      const listings = document.querySelectorAll('[class*="listingCard"], [class*="searchResults"] li');
      
      listings.forEach((listing, index) => {
        if (index > 50) return; // Max 50 ilan
        
        try {
          // Title/fiyat bilgisi
          const titleEl = listing.querySelector('[class*="title"], h3');
          const priceEl = listing.querySelector('[class*="price"]');
          
          const title = titleEl?.textContent?.trim() || '';
          const priceText = priceEl?.textContent?.trim() || '';
          
          // Fiyat parse et
          const priceMatch = priceText.match(/([0-9.]+)/);
          const price = priceMatch ? parseInt(priceMatch[1].replace(/\\./g, '')) * 1000000 : 0;
          
          // mÂ² ve oda bilgisi
          const sqmMatch = title.match(/(\\d+)\\s*mÂ²/i);
          const roomsMatch = title.match(/(\\d\\+\\d)/);
          
          if (price > 0 && sqmMatch && roomsMatch) {
            items.push({
              title,
              price,
              sqm: parseInt(sqmMatch[1]),
              rooms: roomsMatch[1],
            });
          }
        } catch (e) {
          // Skip bu item
        }
      });
      
      return items;
    });

    properties.push(...scrapedData);
    console.log(\`[Scraper] Found \${properties.length} properties\`);

    await page.close();
  } catch (error) {
    console.error('[Scraper] Error:', error);
    throw error;
  } finally {
    if (browser) {
      await browser.close();
    }
  }

  return properties;
}

// Verileri analiz et
function analyzeProperties(properties: ScrapedProperty[]): MarketStats[] {
  if (properties.length === 0) {
    throw new Error('No properties found');
  }

  const groupedByRooms = new Map<string, ScrapedProperty[]>();

  // Oda sayÄ±sÄ±na gÃ¶re grupla
  properties.forEach((prop) => {
    if (!groupedByRooms.has(prop.rooms)) {
      groupedByRooms.set(prop.rooms, []);
    }
    groupedByRooms.get(prop.rooms)!.push(prop);
  });

  const stats: MarketStats[] = [];

  groupedByRooms.forEach((props, rooms) => {
    const prices = props.map((p) => p.price);
    const sqms = props.map((p) => p.sqm);

    const avgPrice = Math.round(prices.reduce((a, b) => a + b, 0) / prices.length);
    const minPrice = Math.min(...prices);
    const maxPrice = Math.max(...prices);
    const medianPrice = prices.sort((a, b) => a - b)[Math.floor(prices.length / 2)];
    const avgSqm = sqms.reduce((a, b) => a + b, 0) / sqms.length;
    const pricePerSqm = Math.round(avgPrice / avgSqm);

    stats.push({
      rooms,
      age_range: 'new', // Simplified, can be enhanced
      average_price: avgPrice,
      min_price: minPrice,
      max_price: maxPrice,
      median_price: medianPrice,
      price_per_sqm: pricePerSqm,
      sample_size: props.length,
    });
  });

  return stats;
}

// Cron handler
export async function GET(request: NextRequest) {
  const startTime = Date.now();
  const supabase = createClient();

  try {
    // Cron secret kontrolÃ¼
    const authHeader = request.headers.get('authorization');
    const cronSecret = process.env.CRON_SECRET;
    
    if (!cronSecret || authHeader !== \`Bearer \${cronSecret}\`) {
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
    }

    console.log('[Cron] Sahibinden scraping started...');

    // Marmaris villalar
    const targets = [
      { city: 'muÄŸla', district: 'marmaris', type: 'villa', rooms: ['2+1', '3+1', '4+1', '5+1'] },
    ];

    const results = [];

    for (const target of targets) {
      for (const rooms of target.rooms) {
        try {
          const url = buildSahibindenUrl(target.city, target.district, target.type, rooms);
          
          // Scrape
          const properties = await scrapeProperties(url);

          if (properties.length === 0) {
            throw new Error('No properties found');
          }

          // Analiz
          const stats = analyzeProperties(properties);

          // History'ye kaydet (backup)
          for (const stat of stats) {
            await supabase.from('market_analysis_history').insert({
              city: target.city,
              district: target.district,
              listing_type: target.type,
              rooms: stat.rooms,
              age_range: stat.age_range,
              average_price: stat.average_price,
              min_price: stat.min_price,
              max_price: stat.max_price,
              median_price: stat.median_price,
              price_per_sqm: stat.price_per_sqm,
              sample_size: stat.sample_size,
              snapshot_date: new Date(),
            });
          }

          // Market_analysis gÃ¼ncelle (upsert)
          for (const stat of stats) {
            const { error } = await supabase
              .from('market_analysis')
              .upsert({
                city: target.city,
                district: target.district,
                listing_type: target.type,
                rooms: stat.rooms,
                age_range: stat.age_range,
                average_price: stat.average_price,
                min_price: stat.min_price,
                max_price: stat.max_price,
                median_price: stat.median_price,
                price_per_sqm: stat.price_per_sqm,
                sample_size: stat.sample_size,
                last_scraped: new Date(),
              });

            if (error) {
              console.error('[Cron] Upsert error:', error);
            }
          }

          // Log baÅŸarÄ±
          await supabase.from('scraping_logs').insert({
            city: target.city,
            district: target.district,
            listing_type: target.type,
            status: 'success',
            properties_found: properties.length,
            average_price: stats[0]?.average_price,
            execution_time_ms: Date.now() - startTime,
          });

          results.push({
            target: \`\${target.district}/\${rooms}\`,
            found: properties.length,
            avgPrice: stats[0]?.average_price,
          });

          console.log(\`[Cron] âœ“ \${target.district}/\${rooms}: \${properties.length} properties\`);

          // Rate limiting (Sahibinden'i spam etme)
          await new Promise((resolve) => setTimeout(resolve, 2000));
        } catch (error) {
          console.error(\`[Cron] Error for \${target.district}/\${rooms}:\`, error);

          await supabase.from('scraping_logs').insert({
            city: target.city,
            district: target.district,
            listing_type: target.type,
            status: 'failed',
            error_message: error instanceof Error ? error.message : 'Unknown error',
            execution_time_ms: Date.now() - startTime,
          });
        }
      }
    }

    const totalTime = Date.now() - startTime;
    console.log(\`[Cron] âœ… Scraping completed in \${totalTime}ms\`);

    return NextResponse.json({
      success: true,
      results,
      execution_time_ms: totalTime,
      timestamp: new Date().toISOString(),
    });
  } catch (error) {
    console.error('[Cron] Fatal error:', error);

    return NextResponse.json(
      {
        success: false,
        error: error instanceof Error ? error.message : 'Unknown error',
        timestamp: new Date().toISOString(),
      },
      { status: 500 }
    );
  }
}
\`\`\`

---

GÃ–REV 3: VERCEL.JSON CRON SETUP
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

vercel.json dosyasÄ±nÄ± aÃ§/oluÅŸtur ve gÃ¼ncelle:

\`\`\`json
{
  "crons": [
    {
      "path": "/api/cron/scrape-sahibinden",
      "schedule": "0 0 * * *"
    }
  ]
}
\`\`\`

Bu: "GÃ¼nde 1x, 00:00 UTC'de Ã§alÄ±ÅŸ"

---

GÃ–REV 4: ENVIRONMENT VARIABLES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Vercel Dashboard â†’ Settings â†’ Environment Variables:

Ekle:
- CRON_SECRET = aVerySecureRandomToken123456789ABC (AYNISI!)
- ANTHROPIC_API_KEY = (zaten var)
- SUPABASE_URL = (zaten var)
- SUPABASE_SERVICE_ROLE_KEY = (zaten var)

---

GÃ–REV 5: VERCEL'E DEPLOY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PowerShell'de:

\`\`\`bash
git add .
git commit -m "Add Sahibinden scraper with Vercel cron"
git push
\`\`\`

Vercel otomatik deploy edecek.

---

GÃ–REV 6: CRON JOB TEST
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Vercel Dashboard â†’ Project â†’ Cron Jobs

GÃ¶rÃ¼ntÃ¼:
âœ“ /api/cron/scrape-sahibinden
âœ“ Schedule: 0 0 * * * (GÃ¼nde 1x, 00:00 UTC)
âœ“ Status: Active

Manual test (Vercel Dashboard'da Test butonuna tÄ±kla):

\`\`\`bash
curl -X GET https://realestate-app-prod.vercel.app/api/cron/scrape-sahibinden \\
  -H "Authorization: Bearer aVerySecureRandomToken123456789ABC"
\`\`\`

Beklenen sonuÃ§:
\`\`\`json
{
  "success": true,
  "results": [
    {
      "target": "marmaris/2+1",
      "found": 23,
      "avgPrice": 2800000
    },
    ...
  ],
  "execution_time_ms": 45000,
  "timestamp": "2026-02-07T00:00:00.000Z"
}
\`\`\`

---

GÃ–REV 7: MONITORING & LOGS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Supabase'de ÅŸunu kontrol et:

1. market_analysis tablosu:
   SELECT * FROM market_analysis WHERE district = 'marmaris';
   
   SonuÃ§: 4 satÄ±r (2+1, 3+1, 4+1, 5+1)

2. market_analysis_history tablosu:
   SELECT * FROM market_analysis_history ORDER BY snapshot_date DESC LIMIT 10;
   
   SonuÃ§: Eski snapshots gÃ¶rÃ¼ntÃ¼lenecek

3. scraping_logs tablosu:
   SELECT * FROM scraping_logs ORDER BY scraped_at DESC;
   
   SonuÃ§: BaÅŸarÄ±lÄ± loglar

---

GÃ–REV 8: REALESTATE APP Ä°LE ENTEGRE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Price Analysis API zaten market_analysis'i kullanÄ±yor!
BaÅŸka bir ÅŸey yapmanÄ±z gerekmez.

Sistem otomatik Ã§alÄ±ÅŸacak:

1. 00:00 UTC: Vercel cron Ã§alÄ±ÅŸÄ±r
2. Sahibinden scrape eder
3. market_analysis gÃ¼ncelle
4. User "Fiyat Analizi" tÄ±kladÄ±ÄŸÄ±nda:
   â†’ market_analysis sorgulanÄ±r
   â†’ Fresh data var!

---

DEPLOYMENT CHECKL Ä°ST
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ“ SQL'ler Supabase'de Ã§alÄ±ÅŸtÄ±rÄ±ldÄ± mÄ±?
âœ“ route.ts dosyasÄ± app/api/cron/scrape-sahibinden/ iÃ§inde mi?
âœ“ vercel.json dosyasÄ± gÃ¼ncellendi mi?
âœ“ CRON_SECRET env variable set mi?
âœ“ Git push yapÄ±ldÄ± mÄ±?
âœ“ Vercel deploy tamamlandÄ± mÄ±?
âœ“ Cron job Status: Active mi?
âœ“ Manual test baÅŸarÄ±lÄ± mÄ±?
âœ“ Supabase'de veri gÃ¶rÃ¼nÃ¼yor mu?

---

TIMELINE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ“ SAAT 00:00 UTC: Cron otomatik Ã§alÄ±ÅŸÄ±r
âœ“ SAAT 00:05 UTC: Veriler Supabase'de
âœ“ SAAT 00:10 UTC: Realestate app kullanÄ±ma hazÄ±r
âœ“ HER GÃœN: Tekrar et

---

TESTING SENARYOLARI
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Test 1: Manual Cron Trigger
- Vercel Dashboard'da Test tÄ±kla
- 2-3 dakika bekle
- Supabase'de veri gÃ¶rÃ¼n

Test 2: Price Analysis ile Entegrasyon
- /price-analysis sayfasÄ±na git
- Marmaris, 3+1 Villa seÃ§
- Analiz Yap tÄ±kla
- Fresh market data kullanÄ±lÄ±yor mu kontrol et

Test 3: History Tracking
- GÃ¼nde 2 kez manuel test yap
- 2 gÃ¼n sonra history'de iki snapshot olacak
- Fiyat deÄŸiÅŸimleri gÃ¶rÃ¼lecek

---

MONITORING & TROUBLESHOOTING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

EÄŸer veri gelmezse:

1. Vercel logs kontrol et:
   vercel logs https://realestate-app-prod.vercel.app

2. Scraping logs:
   SELECT * FROM scraping_logs WHERE status != 'success';

3. Manual test:
   curl -X GET https://realestate-app-prod.vercel.app/api/cron/scrape-sahibinden \\
     -H "Authorization: Bearer CRON_SECRET"

4. Ä°Ã§in hÄ±zlÄ± kontrol:
   - Ä°nternet baÄŸlantÄ±sÄ± var mÄ±?
   - Supabase eriÅŸilebilir mi?
   - Rate limiting var mÄ±?

---

NEXT STEPS (Gelecek)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Åu anda: Marmaris Villalar
Sonra ekle:
- Ä°stanbul (Maltepe, BeÅŸiktaÅŸ, etc)
- Ankara Ã‡ankaya
- Ä°zmir Alsancak
- Antalya KonyaaltÄ±
- MuÄŸla Bodrum

Her ÅŸehir iÃ§in aynÄ± script, sadece URL deÄŸiÅŸir.

---

BAÅARILI DEPLOYMENT SONUCU
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… GÃ¼nde 1x otomatik scraping
âœ… Supabase'de fresh market data
âœ… Price Analysis instant hesaplama
âœ… History tracking (analytics iÃ§in)
âœ… Error logging (monitoring iÃ§in)
âœ… Zero manual work

= Sistem automatic, reliable, scalable
```

---

## ğŸ“ Ã–ZET

Bu prompt 8 gÃ¶revde complete sistem kuruyor:

| GÃ¶rev | YÄ±l | Status |
|-------|-----|--------|
| 1 | Database schema | SQL |
| 2 | Vercel cron function | TypeScript |
| 3 | Cron schedule | JSON |
| 4 | Environment vars | Setup |
| 5 | Deployment | Git push |
| 6 | Testing | Manual |
| 7 | Monitoring | Supabase |
| 8 | Integration | Automatic |

---

## ğŸš€ YAPTICAGIN

```
1. Bu promptu Antigravity'ye yapÄ±ÅŸtÄ±r
2. RUN tÄ±kla
3. Bitene kadar bekle (~2 saat)
4. Test et
5. Deployed! âœ“
```

---

## âœ¨ SONUÃ‡

**GÃ¼nde 1x otomatik Marmaris villa scraping!**

- Sahibinden'den veri Ã§ek
- Supabase'e yaz
- Price Analysis kullanÄ±r
- History sakla (analytics iÃ§in)
- Zero manual work

= Production-ready, fully automated system!

ğŸ”¥ **Hadi baÅŸlatalÄ±m!** ğŸ”¥
